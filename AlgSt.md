# Алгоритмы и структуры данных


## 1. Оценка сложности алгоритма по времени
**Оценка сложности *по времени*** - сколько операций выполняет программа в зависимости от **количества принимаемых данных**.

- 1 операция — 1 пункт сложности
- 1 итерация = $k$ операций в итерации — $k$ пунктов сложности
- Условие = $k$ логических операций и действий — $k$ пунктов сложности

**T(n)** — функция, описывающая сложность алгоритма *в зависимости **от количества** принимаемых данных*. <br/>
Алгоритмы классифицируют в соответствии с их **временной сложностью**. <br/>
**Точная** оценка алгоритма, тогда и только тогда, когда, верхняя граница $O(n)$ и нижняя граница $\Omega (n)$ ***совпадают***. <br/>

| | |
|-|-|
| <img src="img/complexity_table.png" width="512"> | <img src="img/bigOgraph.png" width="512" center> |

**Порядок роста** описывает то, как сложность алгоритма растет с увеличением количества входных данных чаще он представлен в виде О-нотации. **Используем высшую степень, как порядок роста**, потому что она сильнее всех влияет на то, как сложность будет изменяться. <br/>
> [Ссылка на видео лекции КТ](https://youtu.be/8BniwdaAUMc?list=PLrS21S1jm43jz48qjdfYNpuIPgL3lNJ_o) <br/>
> [Сыллка на лекцию Нияза Нигматуллина (CSC)](https://www.youtube.com/watch?v=k850DNwR9xw) <br/>


## 2. Оценка сложности алгоритма по памяти.

Оценка сложности по памяти - сколько занимает памяти алгоритм.

- 1 переменная — 1 пункт сложности
- Массив размером n — n пунктов сложности
- Строка длинной n — n пунктов сложности

Оценка сложности алгоритма по памяти оценивает только **дополнительную память**, используемую алгоритмом. $М(n)$ — функция, оценивающая сложность по памяти. <br/>

Есть **3 функции** оценивающие память: $O$, $\Theta$, $\Gamma$. <br/>

Так же, как и в случае с оценкой по времени:
1. $O$ - верхняя граница
2. $\Theta$ - точная оценка
3. $\Gamma$ - нижняя оценка

**NB! РЕКУРСИВНЫЙ ВЫЗОВ ТРАТИТ ПАМЯТЬ**

> <img src="img/bigOmemory.png" width="512">


## 3. Сортировка вставками

> <img src="img/insertionSort.gif" width="512">

### Принцип сортировки вставками:
- Инвариант*: первый элемент считается отсортированным.
- Просматриваем элементы слева направо от `j + 1` и до конца.
- Выполняем вставку отсортированного элемента в отсортированную часть
- После вставки увеличиваем отсортированную часть на 1.

***Инвариант** - утверждение, которое верно **до** выполнения цикла, **во время** выполнения цикла и **после** выполнения цикла.

### Cложность:
**По времени:**
> - Лучший случай: $O(n)$ (если массив и так отсортирован).
> - Средний случай: $O(n^2)$.
> - Худший случай: $O(n^2)$ (если массив отсортирован наоборот). <br/>

**По памяти:**
> - Во всех случаях $O(1)$, потому что используем одну переменную во всех случаях.

### Устойчивость - УСТОЙЧИВАЯ

### Реализации:
- Меняем элемент, который хотим вставить каждый раз при сравнении его с другими элементами
- Сравниваем элемент с элементами отсортированной части и двигаем её пока не найдем позицию нашего элемента.

### Псевдокод:
Реализация первого алгоритма взятая с [викиконспектов](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B2%D1%81%D1%82%D0%B0%D0%B2%D0%BA%D0%B0%D0%BC%D0%B8) и презы Антона.
```
function insertionSort(a):
  for i = 1 to n
    j = i - 1
    while j >= 0 and a[j] > a[j + 1] 
      swap(a[j], a[j + 1])
      j--
```


## 4. Сортировка слиянием

> <img src="img/mergeSort.gif" width="512">

### Метод декомпозиции: разделяй и властвуй
> 1. Задача разбивается на несколько меньших экземпляров той же задачи.
> 2. Решаются сформированные меньшие экземпляры задачи (обычно рекурсивно).
> 3. При необходимости решение формируется как комбинация решений меньших экземпляров задачи.

Задачу сортировки массива также можно решить с помощью метода декомпозиции. Примером такого решения является *сортировка слиянием*.

### Принцип сортировки слиянием:
> - На рекурсивном спуске разбиваем массив пополам пока длина итоговых подмассивов не будет равна 1.
> - На рекурсивном подъёме сливаем полученные массивы в отсортированный массив.

> <img src="img/mergeSortRecursion.png" width="512"> <br/>
> Рекурсивный спуск (красный) и рекурсивный подъем (зеленый).

### Нерекурсивный метод
Нерекурсивный метод работает оптимальнее, потому что не использует память, которую использовал бы для вызова функций. В итеративной реализации мы разбиваем массив на подмассивы длины 1. Вместе сливаем четные и нечетные подмассивы. После этого мы умножаем длину подмассива на 2 и повторяем процедуру слияния до тех пор, пока не отсортируется массив.

> <img src="img/iterativeMergeSort.jpg" width="512"> <br/>
> Итеративная сортировка слиянием.

### Сложность алгоритма:
**Сложность по времени:**
> - Во всех случаях сложность: $O(n \cdot logn)$, где $n$ это для слияния, а $logn$ для разбиения.

**Сложность по памяти:**
> - Сложность $O(n)$, потому что нужен вспомогательный массив.
> - Существует реализация без доп. массива, но лучше об этом не говорить на защите...

### Устойчивость - УСТОЙЧИВАЯ

### Псевдокод:

#### Слияние
Идея слияния в том, чтобы соединять два отсортированных подмассива в один большой отсортированный подмассив.

Алгоритм слияния с [викиконспектов](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D1%81%D0%BB%D0%B8%D1%8F%D0%BD%D0%B8%D0%B5%D0%BC).
```
function merge(a : int[n]; left, mid, right : int):
    it1 = 0
    it2 = 0
    result : int[right - left]
  
    while left + it1 < mid and mid + it2 < right
        if a[left + it1] < a[mid + it2]
            result[it1 + it2] = a[left + it1]
            it1 += 1
        else
            result[it1 + it2] = a[mid + it2]
            it2 += 1
  
    while left + it1 < mid
        result[it1 + it2] = a[left + it1]
        it1 += 1
  
    while mid + it2 < right
        result[it1 + it2] = a[mid + it2]
        it2 += 1
  
    for i = 0 to it1 + it2
        a[left + i] = result[i]
```

#### Рекурсивный алгоритм
Рекурсивный алгоритм с [викиконспектов](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D1%81%D0%BB%D0%B8%D1%8F%D0%BD%D0%B8%D0%B5%D0%BC).
```
function mergeSortRecursive(a : int[n]; left, right : int):
    if left + 1 >= right
        return
    mid = (left + right) / 2
    mergeSortRecursive(a, left, mid)
    mergeSortRecursive(a, mid, right)
    merge(a, left, mid, right)
```

#### Нерекурсивный алгоритм
Нерекурсивный алгоритм с [викиконспектов](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D1%81%D0%BB%D0%B8%D1%8F%D0%BD%D0%B8%D0%B5%D0%BC).
```
function mergeSortIterative(a : int[n]):
    for i = 1 to n, i *= 2
        for j = 0 to n - i, j += 2 * i
            merge(a, j, j + i, min(j + 2 * i, n))
```

> [Ссылка на видео лекции КТ](https://www.youtube.com/watch?v=8BniwdaAUMc&list=PLrS21S1jm43jz48qjdfYNpuIPgL3lNJ_o) <br/>
> [Сыллка на лекцию Нияза Нигматуллина (CSC)](https://www.youtube.com/watch?v=MMBi2m2RHrQ&list=PLlb7e2G7aSpTZN_zRrbpVJUvB-pTuM_VL&index=2)


## 5. Быстрая сортировка

> <img src="img/quickSort.gif" width="512"> <br/>
> Работа быстрой сортировки.
> Быстрая сортировка также является примером метода "разделяй в властвуй".

### Почему быстрая сортировка названа "быстрой"?
!TODO

### Нерекурсивный метод
!TODO

### Сложность алгоритма:
**Сложность по времени:**
> - Лучший случай: $O(n \cdot logn)$.
> - Средний случай: $O(n \cdot logn)$.
> - Худший случай: $O(n^2)$ (anti quick sort).

**Сложность по памяти:**
> - Лучший случай: $O(logn)$.
> - Средний случай: $O(logn)$.
> - Худший случай: $O(n)$ (anti quick sort).

$O(logn)$ памяти расходуется на рекурсивные вызовы.

### Anti Quick Sort
Худший случай. Если каждый раз мы будем выбирать опорным элементом максимальный, то массив будет разбиваться на два подмассива: в одном будет одно значение - опорный элемент, а в другом будут остальные значения.

Для построения такого массива нужно итеративно вставлять в середину (место опорного) больший элемент. Псевдокод мой.
```
function AntiQuickSort(a: int[n]):
    a[0] = 1
    a[1] = 2

    for i = 2 to n
        a[i] = i + 1
        swap(a[i], a[i / 2])
```

### Устойчивость - НЕ УСТОЙЧИВАЯ

### Псевдокод
Псевдокод с [википедии](https://ru.wikipedia.org/wiki/%D0%91%D1%8B%D1%81%D1%82%D1%80%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0).
```
 algorithm quicksort(A, low, high) is
    if low < high then
        p:= partition(A, low, high)
        quicksort(A, low, p)
        quicksort(A, p + 1, high)
```

#### Разбиение Ломуто:
За опорный элемент берется последний элемент неотсортированного подмассива. На место элемента `a[i]` ищется элемент, меньший либо равный опорному. Если он нахоодится, мы свапаем `a[i]` и `a[j]`. Как только мы доходим до конца массива, мы свапаем опорный с `a[i]`. После этого возвращаем индекс `i`.

Псевдокод с [википедии](https://ru.wikipedia.org/wiki/%D0%91%D1%8B%D1%81%D1%82%D1%80%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0).
```
algorithm partition(A, low, high) is
    pivot := A[high]
    i := low
    for j := low to high - 1 do
        if A[j] <= pivot then
            swap A[i] with A[j]
            i := i + 1
    swap A[i] with A[high]
    return i
```

#### Разбиение Хоара:
Разбиение Хоара (оригинальное) эффективнее Ломуто, так как происходит в три раза меньше обменов элементов, так же оно эффективнее, когда все элементы равны.

Серединный элемент выбирается опорным (есть оптимизация, где выбирается медиана из первого, последнего и серединного). Есть два индекса: `i` и `j`. `a[i]` меньше опорного и расположен в начале массива. `a[j]` больше опорного и расположен в конце массива. Если `a[i]` больше опорного, а `a[j]` меньше опорного, то они меняются местами. Если `i` и `j` пересекаются, то цикл завершается.

**NB! Конечная позиция опроного элемента может не совпадать с серединой массива.**

Псевдокод с [википедии](https://ru.wikipedia.org/wiki/%D0%91%D1%8B%D1%81%D1%82%D1%80%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0).
```
algorithm partition(A, low, high) is
   pivot:= A[(low + high) / 2]
   i:= low
   j:= high
   loop forever
       
       while A[i] < pivot 
              i:= i + 1
       while A[j] > pivot
              j:= j - 1
       if i >= j then
           return j
       swap A[i++] with A[j--]
```

> [Ссылка на видео лекции КТ](https://www.youtube.com/watch?v=CWiDEus3rDA&list=PLrS21S1jm43jz48qjdfYNpuIPgL3lNJ_o&index=3) <br/>
> [Ссылка на лекцию Нияза Нигматуллина (CSC)](https://www.youtube.com/watch?v=kaIP2dkBlbQ&list=PLlb7e2G7aSpTZN_zRrbpVJUvB-pTuM_VL&index=3)


## 6. Сортировка подсчетом

> <img src="img/countingSort.gif" width="512"> <br/>
> Сортировка подсчетом 

**Есть 2 вида сортировки:**
- Не устойчивая
- Устойчивая

### 1. Не устойчивая  

**Принцип работы:** 

Мы создаём доп. массив длинны $K$, где к это мощность используемого алфавита. Например, если мы знаем, что в массиве хранятся только числа от 0-9, то доп. массив у нас будет на 10 элементов. Далее проходимся по нашему исходному массиву и инициализируем доп. массив так, чтобы число $i$ встречалось в исходном массиве $C[i]$ раз.

Далее просто пробегаемся по доп. массиву и выводим  $c[i]$ раз $i$.

### 2. Устойчивая

Начинается, как и неустойчивая, мы так же заполняем доп. массив, но потом мы пробегаемся по нему еще раз от 1 до (доп_мас.size() - 1) и каждому элемент становится равен себе + значение в предыдущей ячейке. Таким образом у нас в $C[i]$ ячейке лежит $id+1$ ячейки в исходном массиве, где после сортировки должен лежать $i$-й элемент. Далее мы создаем новый массив с результатом сортировки просто пробегаемся от (мас.size() - 1) до 0 и ставим элемент из исходного массива (i) на $C[i]-1$ позицию в массив с результатом сортировки.

### Cложность алгоритмов:
#### 1. НЕ устойчивая
**Сложность по времени:** <br/>
$O(n + k)$, т.к. время работы зависит от того,  насколько большой алфавит нам придется взять для составления доп. массива <br/>

**Сложность по памяти:** <br/>
$O(k)$ - на дополнительный массив <br/>
<br/>

#### 2. Устойчивая
**Сложность по времени:** <br/>
$O(k)$

**Сложность по памяти:**
$O(n + k)$, $k$ элементов на доп. массив + $n$ на основной

***В основном применяется, когда $k == n$ (мощность алфавита равна входным данным)***

### Псевдокод:
**Простая сортировка подсчетом (псевдокод с wikipedia.org) - НЕ устойчивая реализация**
```
SimpleCountingSort:
    for i = 0 to k
        C[i] = 0;
    for i = 0 to n - 1
        C[A[i]] = C[A[i]] + 1;
    b = 0;
    for j = 0 to k
        for i = 0 to C[j] - 1
            A[b] = j;
            b = b + 1;
```

**Устойчивая реализация (псевдокод с wikipedia.org)**
```
StableCountingSort
    for i = 0 to k - 1
        C[i] = 0;
    for i = 0 to n - 1
        C[A[i]] = C[A[i]] + 1;
    for j = 1 to k - 1
        C[j] = C[j] + C[j - 1];
    for i = n - 1 to 0
        C[A[i]] = C[A[i]] - 1;
        B[C[A[i]]] = A[i];
```


## 7. Цифровая сортировка

> <img src="img/radixSort.gif" width="512"> <br/>
> **Цифровая сортировка** - один из алгоритмов сортировки, использующих внутреннюю структуру сортируемых объектов.

**NB! Обязательно используем линейные сортировки.**

> <img src="img/radixsort.png" width="512">


## 8. Стек


## 9. Очередь


## 10. Односвязный список


## 11. Двусвязный список


## 12. Циклический список


## 13. Стек на списках


## 14. Очередь на списках

