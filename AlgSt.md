# Алгоритмы и структуры данных


## 1. Оценка сложности алгоритма по времени
**Оценка сложности *по времени*** - сколько операций выполняет программа в зависимости от **количества принимаемых данных**.

- 1 операция — 1 пункт сложности
- 1 итерация = $k$ операций в итерации — $k$ пунктов сложности
- Условие = $k$ логических операций и действий — $k$ пунктов сложности

**T(n)** — функция, описывающая сложность алгоритма *в зависимости **от количества** принимаемых данных*. <br/>
Алгоритмы классифицируют в соответствии с их **временной сложностью**. <br/>
**Точная** оценка алгоритма, тогда и только тогда, когда, верхняя граница $O(n)$ и нижняя граница $\Omega (n)$ ***совпадают***. <br/>

| | |
|-|-|
| <img src="img/complexity_table.png" width="512"> | <img src="img/bigOgraph.png" width="512" center> |

**Порядок роста** описывает то, как сложность алгоритма растет с увеличением количества входных данных чаще он представлен в виде О-нотации. **Используем высшую степень, как порядок роста**, потому что она сильнее всех влияет на то, как сложность будет изменяться. <br/>
> [Ссылка на видео лекции КТ](https://youtu.be/8BniwdaAUMc?list=PLrS21S1jm43jz48qjdfYNpuIPgL3lNJ_o) <br/>
> [Сыллка на лекцию Нияза Нигматуллина (CSC)](https://www.youtube.com/watch?v=k850DNwR9xw) <br/>


## 2. Оценка сложности алгоритма по памяти.

Оценка сложности по памяти - сколько занимает памяти алгоритм.

- 1 переменная — 1 пункт сложности
- Массив размером n — n пунктов сложности
- Строка длинной n — n пунктов сложности

Оценка сложности алгоритма по памяти оценивает только **дополнительную память**, используемую алгоритмом. $М(n)$ — функция, оценивающая сложность по памяти. <br/>

Есть **3 функции** оценивающие память: $O$, $\Theta$, $\Gamma$. <br/>

Так же, как и в случае с оценкой по времени:
1. $O$ - верхняя граница
2. $\Theta$ - точная оценка
3. $\Gamma$ - нижняя оценка

**NB! РЕКУРСИВНЫЙ ВЫЗОВ ТРАТИТ ПАМЯТЬ**

> <img src="img/bigOmemory.png" width="512">


## 3. Сортировка вставками

> <img src="img/insertionSort.gif" width="512">

### Принцип сортировки вставками:
- Инвариант*: первый элемент считается отсортированным.
- Просматриваем элементы слева направо от `j + 1` и до конца.
- Выполняем вставку отсортированного элемента в отсортированную часть
- После вставки увеличиваем отсортированную часть на 1.

***Инвариант** - утверждение, которое верно **до** выполнения цикла, **во время** выполнения цикла и **после** выполнения цикла.

### Cложность:
**По времени:**
> - Лучший случай $O(n)$ (если массив и так отсортирован).
> - Средний случай $O(n^2)$.
> - Худший случай (если массив отсортирован наоборот) $O(n^2)$. <br/>

**По памяти:**
> - Во всех случаях $O(1)$, потому что используем одну переменную во всех случаях.

### Устойчивость
***УСТОЙЧИВАЯ***

### Реализации:
- Меняем элемент, который хотим вставить каждый раз при сравнении его с другими элементами
- Сравниваем элемент с элементами отсортированной части и двигаем её пока не найдем позицию нашего элемента.

### Псевдокод:
Реализация первого алгоритма взятая с [викиконспектов](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B2%D1%81%D1%82%D0%B0%D0%B2%D0%BA%D0%B0%D0%BC%D0%B8) и презы Антона.
```
function insertionSort(a):
  for i = 1 to n
    j = i - 1
    while j >= 0 and a[j] > a[j + 1] 
      swap(a[j], a[j + 1])
      j--
```


## 4. Сортировка слиянием

> <img src="img/mergeSort.gif" width="512">

### Метод декомпозиции: разделяй и властвуй
> 1. Задача разбивается на несколько меньших экземпляров той же задачи.
> 2. Решаются сформированные меньшие экземпляры задачи (обычно рекурсивно).
> 3. При необходимости решение формируется как комбинация решений меньших экземпляров задачи.

Задачу сортировки массива также можно решить с помощью метода декомпозиции. Примером такого решения является *сортировка слиянием*.

### Принцип сортировки слиянием:
> - На рекурсивном спуске разбиваем массив пополам пока длина итоговых подмассивов не будет равна 1.
> - На рекурсивном подъёме сливаем полученные массивы в отсортированный массив.

> <img src="img/mergeSortRecursion.png" width="512"> <br/>
> Рекурсивный спуск (красный) и рекурсивный подъем (зеленый).

### Процедура слияния
!TODO

### Нерекурсивный метод
Нерекурсивный метод работает оптимальнее, потому что не использует память, которую использовал бы для вызова функций. В итеративной реализации мы разбиваем массив на подмассивы длины 1. Вместе сливаем четные и нечетные подмассивы. После этого мы умножаем длину подмассива на 2.

> <img src="img/iterativeMergeSort.jpg" width="512"> <br/>
> Итеративная сортировка слиянием.

### Сложность алгоритма:
**Сложность по времени:**
> - Во всех случаях сложность: $O(n \cdot logn)$, где n это для слияния, а $logn$ для разбиения.

**Сложность по памяти:**
> - Сложность $O(n)$, потому что нужен вспомогательный массив.
> - Существует реализация без доп. массива, но лучше об этом не говорить на защите...

### Устойчивость
***УСТОЙЧИВАЯ***

### Псевдокод:
Алгоритм слияния с [викиконспектов](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D1%81%D0%BB%D0%B8%D1%8F%D0%BD%D0%B8%D0%B5%D0%BC).
```
function merge(a : int[n]; left, mid, right : int):
    it1 = 0
    it2 = 0
    result : int[right - left]
  
    while left + it1 < mid and mid + it2 < right
        if a[left + it1] < a[mid + it2]
            result[it1 + it2] = a[left + it1]
            it1 += 1
        else
            result[it1 + it2] = a[mid + it2]
            it2 += 1
  
    while left + it1 < mid
        result[it1 + it2] = a[left + it1]
        it1 += 1
  
    while mid + it2 < right
        result[it1 + it2] = a[mid + it2]
        it2 += 1
  
    for i = 0 to it1 + it2
        a[left + i] = result[i]
```

Рекурсивный алгоритм с [викиконспектов](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D1%81%D0%BB%D0%B8%D1%8F%D0%BD%D0%B8%D0%B5%D0%BC).
```
function mergeSortRecursive(a : int[n]; left, right : int):
    if left + 1 >= right
        return
    mid = (left + right) / 2
    mergeSortRecursive(a, left, mid)
    mergeSortRecursive(a, mid, right)
    merge(a, left, mid, right)
```

Нерекурсивный алгоритм с [викиконспектов](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D1%81%D0%BB%D0%B8%D1%8F%D0%BD%D0%B8%D0%B5%D0%BC).
```
function mergeSortIterative(a : int[n]):
    for i = 1 to n, i *= 2
        for j = 0 to n - i, j += 2 * i
            merge(a, j, j + i, min(j + 2 * i, n))
```

> [Ссылка на видео лекции КТ](https://www.youtube.com/watch?v=8BniwdaAUMc&list=PLrS21S1jm43jz48qjdfYNpuIPgL3lNJ_o) <br/>
> [Сыллка на лекцию Нияза Нигматуллина (CSC)](https://www.youtube.com/watch?v=MMBi2m2RHrQ&list=PLlb7e2G7aSpTZN_zRrbpVJUvB-pTuM_VL&index=2)


## 5. Быстрая сортировка

### Принцип работы Быстрой сортировки:

<img src="img/quickSort.gif" width="512">

### Сложность алгоритма:

**Сложность по времени:**
- Лучший: $O(n \cdot logn)$
- Средний: $O(n \cdot logn)$
- Худшая: $O(n^2)$

**Сложность по памяти:**
- $O(n)$ - дополнительная??? память на массив.
- $O(logn)$ - необходимо памяти на спуск.

Требует лишь $O(1)$ дополнительной памяти для своей работы (неулучшенный рекурсивный алгоритм - в худшем случае $O(n)$ памяти

### Устойчивость
***НЕ УСТОЙЧИВ***


### Разбиение Ломуто:
- За опорный элемент берётся последний неотсортированного массива
- Ставим два указателя $i$ И $j$ на первый элемент, где $j$ — указатель на первый элемент, который больше опорного, а $i$ указатель на часть массива без опорного.
- Если элемент под $i$-тым индексом меньше опорного мы свапаем его с $j$-тым элементом и увеличиваем оба указателя на 1.
- Если элемент под $i$-тым указателем больше опорного, то увеличиваем только $i$-тый указатель.
- Как только мы дошли $i$-тым указателем до последнего, то свапаем последний элемент с $j$-тым.
- Рекурсивно выполняем Быструю сортировку для массива 0 до $j-1$ элемента и для $j + 1$ до $i$.

#### Псевдокод с wikipedia.com
```
algorithm partition(A, low, high) is
    pivot := A[high]
    i := low
    for j := low to high - 1 do
        if A[j] ≤ pivot then
            swap A[i] with A[j]
            i := i + 1
    swap A[i] with A[high]
    return i
```

### Разбиение Хоара:
#### Псевдокод с wikipedia.com
```
algorithm quicksort(A, lo, hi) is
   if lo < hi then
       p:= partition(A, lo, hi)
       quicksort(A, lo, p)
       quicksort(A, p + 1, hi)
       
algorithm partition(A, low, high) is
   pivot:= A[(low + high) / 2]
   i:= low
   j:= high
   loop forever
       
       while A[i] < pivot 
              i:= i + 1
       while A[j] > pivot
              j:= j - 1
       if i >= j then
           return j
       swap A[i++] with A[j--]
```

### Код:
> вызывать так: QuickSort(array, 0, length - 1) <br/>
> n - длина массива arr

```cpp
void QuickSort(int* arr, int left, int right) {
    int pivot = arr[(left + right) / 2];
    int i = left;
    int j = right;
    while (i <= j) {
        while (arr[i] < pivot) {
            i++;
        }
        while (arr[j] > pivot) {
            j--;
        }
        if (i <= j) {
            std::swap(arr[i], arr[j]);
            i++;
            j--;
        }
    }
    if (left < j) {
        QuickSort(arr, left, j);
    }
    if (right > i) {
        QuickSort(arr, i, right);
    }
}
```

> [Ссылка на видео лекции КТ](https://www.youtube.com/watch?v=CWiDEus3rDA&list=PLrS21S1jm43jz48qjdfYNpuIPgL3lNJ_o&index=3) <br/>
> [Ссылка на лекцию Нияза Нигматуллина (CSC)](https://www.youtube.com/watch?v=kaIP2dkBlbQ&list=PLlb7e2G7aSpTZN_zRrbpVJUvB-pTuM_VL&index=3)

## 6. Сортировка подсчетом

> <img src="img/countingSort.gif" width="512">

**Есть 2 вида сортировки:**
- Не устойчивая
- Устойчивая

### 1. Не устойчивая  

**Принцип работы:** 

Мы создаём доп. массив длинны $K$, где к это мощность используемого алфавита. Например, если мы знаем, что в массиве хранятся только числа от 0-9, то доп. массив у нас будет на 10 элементов. Далее проходимся по нашему исходному массиву и инициализируем доп. массив так, чтобы число $i$ встречалось в исходном массиве $C[i]$ раз.

Далее просто пробегаемся по доп. массиву и выводим  $c[i]$ раз $i$.

### 2. Устойчивая

Начинается, как и неустойчивая, мы так же заполняем доп. массив, но потом мы пробегаемся по нему еще раз от 1 до (доп_мас.size() - 1) и каждому элемент становится равен себе + значение в предыдущей ячейке. Таким образом у нас в $C[i]$ ячейке лежит $id+1$ ячейки в исходном массиве, где после сортировки должен лежать $i$-й элемент. Далее мы создаем новый массив с результатом сортировки просто пробегаемся от (мас.size() - 1) до 0 и ставим элемент из исходного массива (i) на $C[i]-1$ позицию в массив с результатом сортировки.

### Cложность алгоритмов:
#### 1. НЕ устойчивая
**Сложность по времени:** <br/>
$O(n + k)$, т.к. время работы зависит от того,  насколько большой алфавит нам придется взять для составления доп. массива <br/>

**Сложность по памяти:** <br/>
$O(k)$ - на дополнительный массив <br/>
<br/>

#### 2. Устойчивая
**Сложность по времени:** <br/>
$O(k)$

**Сложность по памяти:**
$O(n + k)$, $K$ элементов на доп. массив + $n$ на основной

***В основном применяется, когда $k == n$ (мощность алфавита равна входным данным)***

### Код:
**Простая сортировка подсчетом (псевдокод с wikipedia.org) - НЕ устойчивая реализация**
```cpp
SimpleCountingSort:
    for i = 0 to k
        C[i] = 0;
    for i = 0 to n - 1
        C[A[i]] = C[A[i]] + 1;
    b = 0;
    for j = 0 to k
        for i = 0 to C[j] - 1
            A[b] = j;
            b = b + 1;
```
**Устойчивая реализация (псевдокод с wikipedia.org)**
```cpp
StableCountingSort
    for i = 0 to k - 1
        C[i] = 0;
    for i = 0 to n - 1
        C[A[i]] = C[A[i]] + 1;
    for j = 1 to k - 1
        C[j] = C[j] + C[j - 1];
    for i = n - 1 to 0
        C[A[i]] = C[A[i]] - 1;
        B[C[A[i]]] = A[i];
```
## 7. Цифровая сортировка

| | |
|-|-|
| <img src="img/radixSort.gif" width="512"> | <img src="img/radixsort.png" width="512"> |

**Цифровая сортировка** - один из алгоритмов сортировки, использующих внутреннею структуру сортируемых объектов.

